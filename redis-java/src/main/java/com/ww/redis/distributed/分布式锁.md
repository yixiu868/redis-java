# 分布式锁

## 常见方案

* 1、MySQL（性能低）
* 2、Zookeeper（性能高）
* 3、Redis（性能高）

## Redis分布式锁

### SET命令

```lua
// 一条命令保证原子执行
SET lock 1 EX 10 NX
```

#### 引入问题

* 1、评估操作共享资源的时间不准导致问题；
* 2、一个客户端释放了其他客户端持有的锁；

#### 锁被比人释放怎么办

`解决方法`：客户端在加锁时，设置一个只有自己知道的[`唯一标识`]。

```lua
// 锁的value设置为uuid
SET lock $uuid EX 20 NX
```

```lua
// 锁是自己的，才释放
if redis.get("lock") == $uuid:
	redis.del("lock")
```

Get + Del两条命令，非原子操作，使用lua脚本执行。

```lua
// 判断锁是自己的，才释放
if redis.call("GET", KEYS[1]) == ARGV[1]
then
    return redis.call("DEL", KEYS[1])
else
    return 0
end
```

#### 锁过期时间不好评估怎么办

使用`Redisson`

![474949eea2499abf0d0176c78937d6af_640_wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1](img\474949eea2499abf0d0176c78937d6af_640_wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1.webp)

### 引入Redlock

#### 场景如下

1、客户端1在主库上执行SET命令，加锁成功；

2、此时，主库异常宕机，SET命令还未同步到从库上（主从复制是异步的）；

3、从库被哨兵提升为新主库，这个锁在新主库上，`丢了！！！`

![d53c6eab6ad5aea025795e7a45316357_640_wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1](img\d53c6eab6ad5aea025795e7a45316357_640_wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1.webp)

#### Redlock方案实现前提

* 1、不再需要部署从库和哨兵实例，只部署主库；
* 2、但主库要部署多个，官方推荐至少5个实例；（注意，这里不是Redis Cluster，就是部署5个简单的Redis实例，之间没有任何关系，是一个个孤立的实例）；

##### 整体流程，分为5步：

* 1、客户端先获取[当前时间戳T1]；
* 2、客户端依次向这5个Redis实例发起加锁请求（前面讲到的SET命令），且每个请求会`设置超时时间`（要远小于锁的有效时间），如果一个实例加锁失败，就立即向下一个Redis实例申请加锁；
* 3、如果客户端从`>=3个（大多数）`以上Redis实例加锁成功，再次获取[当前时间戳T2]，如果`T2-T1<锁过期时间`，此时，认为客户端加锁成功，否则认为加锁失败；
* 4、加锁成功，去操作共享资源；
* 5、加锁失败，向[全部节点]发起释放锁请求（前面讲到的Lua脚本失败）。

### Zookeeper分布式锁

#### 优点

* 1、不需要考虑锁过期时间；
* 2、watch机制，加锁失败，可以watch等待锁释放，实现乐观锁；

#### 劣势

* 1、性能不如Redis；
* 2、部署和运维成本高；
* 3、客户端与Zookeeper的长时间失联，锁被释放问题。
  * 客户端与Zookeeper服务器维护一个`Session`，这个Session会依赖客户端[`定时心跳`]来维护连接。

